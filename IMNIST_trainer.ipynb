{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip to ./data/EMNIST/raw/gzip.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/EMNIST/raw/gzip.zip to ./data/EMNIST/raw\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformation: Convert to Tensor and normalize pixel values to [0, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download the EMNIST dataset\n",
    "train_dataset = EMNIST(root='./data', split='byclass', train=True, download=True, transform=transform)\n",
    "test_dataset = EMNIST(root='./data', split='byclass', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.permute(0, 2, 1))  # Rotate to fix orientation\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Step 2: CNN Model Definition\n",
    "class EMNISTCNN(nn.Module):\n",
    "    def __init__(self, num_classes=62):\n",
    "        super(EMNISTCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # Output: (32, 28, 28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # Output: (32, 14, 14)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Output: (64, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # Output: (64, 7, 7)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.5076\n",
      "Epoch 2/10, Loss: 0.3883\n",
      "Epoch 3/10, Loss: 0.3629\n",
      "Epoch 4/10, Loss: 0.3478\n",
      "Epoch 5/10, Loss: 0.3370\n",
      "Epoch 6/10, Loss: 0.3278\n",
      "Epoch 7/10, Loss: 0.3206\n",
      "Epoch 8/10, Loss: 0.3139\n",
      "Epoch 9/10, Loss: 0.3084\n",
      "Epoch 10/10, Loss: 0.3029\n",
      "Accuracy: 86.37%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = EMNISTCNN(num_classes=62).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11829/1919146993.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"emnist_cnn.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EMNISTCNN(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=62, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"emnist_cnn.pth\")\n",
    "model.load_state_dict(torch.load(\"emnist_cnn.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: 2, Predicted: 2\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Example Inference\n",
    "def predict(model, image):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device).unsqueeze(0)  # Add batch dimension\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "# Test the prediction with a single image from the test dataset\n",
    "sample_image, sample_label = test_dataset[random.randint(0,100)]\n",
    "predicted_label = predict(model, sample_image)\n",
    "print(f\"Ground Truth: {sample_label}, Predicted: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define the model architecture (same as during training)\n",
    "class EMNISTCNN(nn.Module):\n",
    "    def __init__(self, num_classes=62):\n",
    "        super(EMNISTCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Load the trained model\n",
    "def load_trained_model(model_path=\"emnist_cnn.pth\"):\n",
    "    model = EMNISTCNN(num_classes=62)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    return model\n",
    "\n",
    "# Preprocess the input numpy array (30x30)\n",
    "def preprocess_cell(cell):\n",
    "    # Ensure the input is a numpy array\n",
    "    assert isinstance(cell, np.ndarray), \"Input must be a numpy array\"\n",
    "    assert cell.shape == (30, 30), \"Input array must be 30x30\"\n",
    "    \n",
    "    # Convert numpy array to Pillow image\n",
    "    image = Image.fromarray(cell).convert('L')  # Convert to grayscale if not already\n",
    "    \n",
    "    # Resize to 28x28 (EMNIST standard size)\n",
    "    image = image.resize((28, 28), Image.ANTIALIAS)\n",
    "    \n",
    "    # Convert to numpy array, normalize to [0, 1], and add channel dimension\n",
    "    image = np.array(image, dtype=np.float32) / 255.0  # Normalize pixel values\n",
    "    image = np.expand_dims(image, axis=0)  # Add channel dimension (1, 28, 28)\n",
    "    \n",
    "    # Convert to PyTorch tensor\n",
    "    image_tensor = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "    return image_tensor\n",
    "\n",
    "# Function to predict the letter in the cell\n",
    "def predict_letter_from_cell(cell, model):\n",
    "    # Preprocess the input cell\n",
    "    image_tensor = preprocess_cell(cell)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "    # Map prediction to the corresponding character\n",
    "    classes = list(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")\n",
    "    predicted_label = classes[predicted.item()]\n",
    "    return predicted_label\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained model\n",
    "    model = load_trained_model(\"emnist_cnn.pth\")\n",
    "    \n",
    "    # Example cell input (replace with actual 30x30 numpy array)\n",
    "    cell = np.random.randint(0, 255, (30, 30), dtype=np.uint8)  # Example random data\n",
    "    \n",
    "    # Predict the letter in the cell\n",
    "    predicted_letter = predict_letter_from_cell(cell, model)\n",
    "    print(f\"Predicted letter: {predicted_letter}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
