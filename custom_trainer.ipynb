{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "charz = ['B', 'U', 'D', 'R', 'K', 'A', 'E', '6', 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, charz, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to the CSV file with image paths and labels.\n",
    "            charz (list): List of characters to include in the dataset.\n",
    "            transform (callable, optional): Optional transform to apply to samples.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.charz = charz\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(charz)}  # Map chars to indices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 0]\n",
    "        label = self.data.iloc[idx, 1]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(os.path.join(\"dataset_\", img_path)).convert(\"L\")  # Grayscale\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Map label to index\n",
    "        label_idx = self.char_to_idx[label]\n",
    "        \n",
    "        return torch.tensor(np.array(image, dtype=np.float32) / 255.0).unsqueeze(0), label_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMNISTCNN(nn.Module):\n",
    "    def __init__(self, num_classes=9):  # Only 9 classes\n",
    "        super(EMNISTCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (if needed)\n",
    "transform = None  # You can add augmentation transforms here\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = CustomDataset(csv_file=\"dataset_/labels.csv\", charz=charz, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2935\n",
      "Epoch 2, Loss: 0.0008\n",
      "Epoch 3, Loss: 0.0003\n",
      "Epoch 4, Loss: 0.0001\n",
      "Epoch 5, Loss: 0.0001\n",
      "Epoch 6, Loss: 0.0000\n",
      "Epoch 7, Loss: 0.0000\n",
      "Epoch 8, Loss: 0.0000\n",
      "Epoch 9, Loss: 0.0000\n",
      "Epoch 10, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = EMNISTCNN(num_classes=len(charz))  # Only 9 classes\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Train for 10 epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader):.4f}\")\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), \"custom_charz.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5155/838208517.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"custom_charz.pth\"))\n"
     ]
    }
   ],
   "source": [
    "# Reload the trained model\n",
    "model = EMNISTCNN(num_classes=len(charz))\n",
    "model.load_state_dict(torch.load(\"custom_charz.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Predict function\n",
    "def predict_letter_from_cell(cell, model, charz):\n",
    "    char_to_idx = {idx: char for idx, char in enumerate(charz)}\n",
    "    image_tensor = preprocess_cell(cell)  # Preprocess the cell\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return char_to_idx[predicted.item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.98"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create test dataset and dataloader\n",
    "test_dataset = CustomDataset(csv_file=\"dataset/labels.csv\", charz=['B', 'U', 'D', 'R', 'K', 'A', 'E', '6', 'N'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Test the model\n",
    "evaluate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
